name: Quality Check

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main", "develop"]

permissions:
  contents: read

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    outputs:
      eslint_errors: ${{ steps.eslint.outputs.errors }}
      eslint_warnings: ${{ steps.eslint.outputs.warnings }}
      ts_errors: ${{ steps.typecheck.outputs.errors }}
      tests_passed: ${{ steps.tests.outputs.passed }}
      rustfmt_ok: ${{ steps.rustfmt.outputs.fmt_ok }}
      clippy_errors: ${{ steps.clippy.outputs.errors }}
      clippy_warnings: ${{ steps.clippy.outputs.warnings }}
      score: ${{ steps.score.outputs.score }}
      grade: ${{ steps.score.outputs.grade }}
      color: ${{ steps.score.outputs.color }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Install Dependencies
        run: cd app && bun install

      # â”€â”€ TypeScript â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Type Check
        id: typecheck
        run: |
          set +e
          cd app
          tsc_out=$(bun run type-check 2>&1)
          echo "$tsc_out"
          # Count error lines (lines containing "error TS")
          err_count=$(echo "$tsc_out" | grep -c "error TS" || true)
          err_count=$(echo "$err_count" | tr -d '\n' | head -1)
          echo "errors=$err_count" >> "$GITHUB_OUTPUT"
          echo "ðŸ“Š TypeScript: $err_count error(s)"

      # â”€â”€ ESLint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Lint (ESLint)
        id: eslint
        run: |
          set +e
          cd app
          # Run ESLint with JSON format, capture output â€“ never fail the step
          eslint_json=$(bun run lint -- --format json 2>/dev/null || true)

          # Fall back: if JSON is empty/invalid, run plain and count manually
          if echo "$eslint_json" | node -e "JSON.parse(require('fs').readFileSync('/dev/stdin','utf8'))" 2>/dev/null; then
            errors=$(echo "$eslint_json" | node -e "
              const d=JSON.parse(require('fs').readFileSync('/dev/stdin','utf8'));
              console.log(d.reduce((s,f)=>s+f.errorCount,0));
            ")
            warnings=$(echo "$eslint_json" | node -e "
              const d=JSON.parse(require('fs').readFileSync('/dev/stdin','utf8'));
              console.log(d.reduce((s,f)=>s+f.warningCount,0));
            ")
          else
            # Plain text fallback
            plain_out=$(bun run lint 2>&1 || true)
            echo "$plain_out"
            errors=$(echo "$plain_out" | grep -c "error" | head -1 || echo "0")
            warnings=$(echo "$plain_out" | grep -c "warning" | head -1 || echo "0")
          fi

          # Sanitize counts
          errors=$(echo "${errors:-0}" | tr -d '\n' | head -1)
          warnings=$(echo "${warnings:-0}" | tr -d '\n' | head -1)

          echo "errors=${errors}" >> "$GITHUB_OUTPUT"
          echo "warnings=${warnings}" >> "$GITHUB_OUTPUT"
          echo "ðŸ“Š ESLint: ${errors} error(s), ${warnings} warning(s)"

      # â”€â”€ Unit Tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Unit Tests
        id: tests
        run: |
          set +e
          cd app
          bun run test
          exit_code=$?
          if [ $exit_code -eq 0 ]; then
            echo "passed=true" >> "$GITHUB_OUTPUT"
            echo "âœ… Tests passed"
          else
            echo "passed=false" >> "$GITHUB_OUTPUT"
            echo "ðŸ“Š Tests failed (score will be affected)"
          fi

      # â”€â”€ Server Build â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Build Server Binary (Linux host)
        run: cd app && bun build src/index.ts --compile --target bun-linux-x64 --outfile src-tauri/bin/zentrio-server-x86_64-unknown-linux-gnu

      # â”€â”€ Rust â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy, rustfmt

      - name: Install System Dependencies
        run: sudo apt-get update && sudo apt-get install -y libglib2.0-dev libgtk-3-dev libwebkit2gtk-4.1-dev libayatana-appindicator3-dev librsvg2-dev

      - name: Rust Cache
        uses: swatinem/rust-cache@v2
        with:
          workspaces: "./app/src-tauri -> target"

      - name: Rust Formatting
        id: rustfmt
        run: |
          set +e
          cd app/src-tauri
          cargo fmt -- --check
          fmt_exit=$?
          if [ $fmt_exit -eq 0 ]; then
            echo "fmt_ok=true" >> "$GITHUB_OUTPUT"
            echo "âœ… Rust formatting OK"
          else
            echo "fmt_ok=false" >> "$GITHUB_OUTPUT"
            echo "ðŸ“Š Rust formatting issues found (score will be affected)"
          fi

      - name: Rust Linting (Clippy)
        id: clippy
        run: |
          set +e
          cd app/src-tauri
          # Use -W warnings so warnings are reported but don't fail
          clippy_out=$(cargo clippy -- -W warnings 2>&1)
          echo "$clippy_out"
          warn_count=$(echo "$clippy_out" | grep -c "^warning" | head -1 || echo "0")
          err_count=$(echo "$clippy_out" | grep -c "^error" | head -1 || echo "0")
          # Sanitize to ensure single integer values
          warn_count=$(echo "$warn_count" | tr -d '\n' | head -1)
          err_count=$(echo "$err_count" | tr -d '\n' | head -1)
          echo "warnings=${warn_count}" >> "$GITHUB_OUTPUT"
          echo "errors=${err_count}" >> "$GITHUB_OUTPUT"
          echo "ðŸ“Š Clippy: ${err_count} error(s), ${warn_count} warning(s)"

      # â”€â”€ Score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Calculate Quality Score
        id: score
        if: always()
        run: |
          # Inputs (default to 0 if not available)
          TS_ERRORS="${{ steps.typecheck.outputs.errors || '0' }}"
          ESLINT_ERRORS="${{ steps.eslint.outputs.errors || '0' }}"
          ESLINT_WARNINGS="${{ steps.eslint.outputs.warnings || '0' }}"
          TESTS_PASSED="${{ steps.tests.outputs.passed || 'false' }}"
          CLIPPY_ERRORS="${{ steps.clippy.outputs.errors || '0' }}"
          CLIPPY_WARNINGS="${{ steps.clippy.outputs.warnings || '0' }}"
          RUSTFMT_OK="${{ steps.rustfmt.outputs.fmt_ok || 'false' }}"

          # Scoring (100 points, deductions):
          #   TypeScript errors:   -10 per error (max -50)
          #   TypeScript warnings: -2 per warning (max -20)
          #   ESLint errors:       -10 per error (max -50)
          #   ESLint warnings:     -3 per warning (max -30)
          #   Tests failed:        -25
          #   Rust fmt issues:     -10
          #   Clippy errors:       -10 per error (max -30)
          #   Clippy warnings:     -3 per warning (max -20)

          python3 - <<'PYEOF'
          import os, math

          ts_err   = int(os.environ.get('TS_ERRORS', '0'))
          esl_err  = int(os.environ.get('ESLINT_ERRORS', '0'))
          esl_warn = int(os.environ.get('ESLINT_WARNINGS', '0'))
          tests_ok = os.environ.get('TESTS_PASSED', 'false') == 'true'
          clip_err = int(os.environ.get('CLIPPY_ERRORS', '0'))
          clip_w   = int(os.environ.get('CLIPPY_WARNINGS', '0'))
          rustfmt_ok = os.environ.get('RUSTFMT_OK', 'false') == 'true'

          score = 100
          score -= min(ts_err   * 10, 50)
          score -= min(esl_err  * 10, 50)
          score -= min(esl_warn * 3,  30)
          if not tests_ok:
              score -= 25
          if not rustfmt_ok:
              score -= 10
          score -= min(clip_err * 10, 30)
          score -= min(clip_w   * 3,  20)

          score = max(0, score)

          if score >= 90:
              grade, color = "A", "brightgreen"
          elif score >= 80:
              grade, color = "B", "green"
          elif score >= 70:
              grade, color = "C", "yellowgreen"
          elif score >= 60:
              grade, color = "D", "yellow"
          elif score >= 40:
              grade, color = "E", "orange"
          else:
              grade, color = "F", "red"

          print(f"Score: {score}/100  Grade: {grade}  Color: {color}")

          # Write to GITHUB_OUTPUT
          with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
              fh.write(f"score={score}\n")
              fh.write(f"grade={grade}\n")
              fh.write(f"color={color}\n")
          PYEOF

  # â”€â”€ Badge update (main branch only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  update-badge:
    name: Update Quality Badge
    runs-on: ubuntu-latest
    needs: quality
    # Only update on push to main (not on PRs, not on develop)
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    permissions:
      contents: read

    steps:
      - name: Push badge JSON to Gist
        env:
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
          GIST_ID: ${{ secrets.QUALITY_BADGE_GIST_ID }}
          SCORE: ${{ needs.quality.outputs.score }}
          GRADE: ${{ needs.quality.outputs.grade }}
          COLOR: ${{ needs.quality.outputs.color }}
        run: |
          # Debug: Show which secrets are set (safely)
          if [ -z "$GIST_TOKEN" ]; then
            echo "âŒ GIST_TOKEN is not set"
          else
            echo "âœ… GIST_TOKEN is set (length: ${#GIST_TOKEN})"
          fi
          
          if [ -z "$GIST_ID" ]; then
            echo "âŒ QUALITY_BADGE_GIST_ID is not set"
          else
            echo "âœ… QUALITY_BADGE_GIST_ID is set: $GIST_ID"
          fi
          
          if [ -z "$GIST_TOKEN" ] || [ -z "$GIST_ID" ]; then
            echo "âš ï¸  GIST_TOKEN or QUALITY_BADGE_GIST_ID secret not set â€“ skipping badge update"
            echo ""
            echo "To fix this, add these secrets to your repository:"
            echo "  - GIST_TOKEN: A GitHub Personal Access Token with 'gist' scope"
            echo "  - QUALITY_BADGE_GIST_ID: The ID of the gist to store the badge JSON"
            exit 0
          fi

          PAYLOAD=$(python3 -c "
          import json, os
          score = os.environ.get('SCORE', '?')
          grade = os.environ.get('GRADE', '?')
          color = os.environ.get('COLOR', 'lightgrey')
          data = {
            'schemaVersion': 1,
            'label': 'code quality',
            'message': f'{score}/100 ({grade})',
            'color': color,
            'cacheSeconds': 60
          }
          print(json.dumps(data))
          ")

          # Escape the payload for the GitHub API
          ESCAPED=$(python3 -c "import json,sys; print(json.dumps(sys.argv[1]))" "$PAYLOAD")

          curl -s -X PATCH \
            -H "Authorization: token $GIST_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/gists/$GIST_ID" \
            -d "{\"files\":{\"quality.json\":{\"content\":$ESCAPED}}}" \
            | python3 -c "import sys,json; d=json.load(sys.stdin); print('âœ… Gist updated:', d.get('html_url','?'))"

      - name: Print score summary
        if: always()
        run: |
          echo "## ðŸ“Š Quality Score" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "| Metric | Value |" >> "$GITHUB_STEP_SUMMARY"
          echo "|--------|-------|" >> "$GITHUB_STEP_SUMMARY"
          echo "| **Score** | **${{ needs.quality.outputs.score }}/100** |" >> "$GITHUB_STEP_SUMMARY"
          echo "| **Grade** | **${{ needs.quality.outputs.grade }}** |" >> "$GITHUB_STEP_SUMMARY"
          echo "| TypeScript errors | ${{ needs.quality.outputs.ts_errors }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| ESLint errors | ${{ needs.quality.outputs.eslint_errors }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| ESLint warnings | ${{ needs.quality.outputs.eslint_warnings }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Tests | ${{ needs.quality.outputs.tests_passed == 'true' && 'âœ… passed' || 'âŒ failed' }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Rust fmt | ${{ needs.quality.outputs.rustfmt_ok == 'true' && 'âœ… OK' || 'âŒ issues' }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Clippy errors | ${{ needs.quality.outputs.clippy_errors }} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Clippy warnings | ${{ needs.quality.outputs.clippy_warnings }} |" >> "$GITHUB_STEP_SUMMARY"
